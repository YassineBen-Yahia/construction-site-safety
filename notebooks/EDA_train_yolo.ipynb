{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:39.118224Z",
     "iopub.status.busy": "2026-01-25T12:10:39.117636Z",
     "iopub.status.idle": "2026-01-25T12:10:40.750408Z",
     "shell.execute_reply": "2026-01-25T12:10:40.749593Z",
     "shell.execute_reply.started": "2026-01-25T12:10:39.118192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:50.259953Z",
     "iopub.status.busy": "2026-01-25T12:10:50.259677Z",
     "iopub.status.idle": "2026-01-25T12:10:50.264993Z",
     "shell.execute_reply": "2026-01-25T12:10:50.264198Z",
     "shell.execute_reply.started": "2026-01-25T12:10:50.259932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data\n",
      "Train Path: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train\n",
      "Valid Path: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid\n",
      "Test Path: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/test\n",
      "Output Path: /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "# Data path\n",
    "data_path = '/kaggle/input/construction-site-safety-image-dataset-roboflow/css-data'\n",
    "# Train, Valid and Test path\n",
    "train_path = os.path.join(data_path, 'train')\n",
    "valid_path = os.path.join(data_path, 'valid')\n",
    "test_path = os.path.join(data_path, 'test')\n",
    "# For saving results\n",
    "output_path = '/kaggle/working'\n",
    "# We can access both images and labels\n",
    "folders = ['images', 'labels']\n",
    "print(\"Data Path: {}\\nTrain Path: {}\\nValid Path: {}\\nTest Path: {}\\nOutput Path: {}\".format(data_path, train_path, valid_path, test_path, output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:50.622855Z",
     "iopub.status.busy": "2026-01-25T12:10:50.622573Z",
     "iopub.status.idle": "2026-01-25T12:10:50.628256Z",
     "shell.execute_reply": "2026-01-25T12:10:50.627467Z",
     "shell.execute_reply.started": "2026-01-25T12:10:50.622831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest', 5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'vehicle'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries of training and classes\n",
    "train_dict = dict(train=0, valid=1, test=2)\n",
    "path_dict = [train_path, valid_path, test_path]\n",
    "class_names = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n",
    "class_dict = dict(zip(range(len(class_names)), class_names))\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:53.111703Z",
     "iopub.status.busy": "2026-01-25T12:10:53.111095Z",
     "iopub.status.idle": "2026-01-25T12:10:53.642877Z",
     "shell.execute_reply": "2026-01-25T12:10:53.642335Z",
     "shell.execute_reply.started": "2026-01-25T12:10:53.111677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Get filenames and labels information\n",
    "# Sorting the filenames will make the labels and images in same order \n",
    "train_filenames = sorted(os.listdir(os.path.join(train_path,folders[0])))\n",
    "valid_filenames = sorted(os.listdir(os.path.join(valid_path, folders[0])))\n",
    "test_filenames = sorted(os.listdir(os.path.join(test_path, folders[0])))\n",
    "train_labels = sorted(os.listdir(os.path.join(train_path, folders[1])))\n",
    "valid_labels = sorted(os.listdir(os.path.join(valid_path, folders[1])))\n",
    "test_labels = sorted(os.listdir(os.path.join(test_path, folders[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:55.126926Z",
     "iopub.status.busy": "2026-01-25T12:10:55.126645Z",
     "iopub.status.idle": "2026-01-25T12:10:55.139870Z",
     "shell.execute_reply": "2026-01-25T12:10:55.139338Z",
     "shell.execute_reply.started": "2026-01-25T12:10:55.126902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One liner for the above code\n",
    "# We can also use list comprehension for this\n",
    "t_f, v_f, te_f = [sorted(os.listdir(os.path.join(path_dict[i], folders[0]))) for i in range(len(path_dict))]\n",
    "t_l, v_l, te_l = [sorted(os.listdir(os.path.join(path_dict[i], folders[1]))) for i in range(len(path_dict))]\n",
    "# Check whether both gives same results in filenames\n",
    "train_filenames==t_f, valid_filenames==v_f, test_filenames==te_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:55.405359Z",
     "iopub.status.busy": "2026-01-25T12:10:55.405050Z",
     "iopub.status.idle": "2026-01-25T12:10:55.413095Z",
     "shell.execute_reply": "2026-01-25T12:10:55.412527Z",
     "shell.execute_reply.started": "2026-01-25T12:10:55.405333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check order in filenames and labels in all splits\n",
    "[item.split('.')[0] for item in train_filenames]==[item.split('.')[0] for item in train_labels],\\\n",
    "[item.split('.')[0] for item in valid_filenames]==[item.split('.')[0] for item in valid_labels],\\\n",
    "[item.split('.')[0] for item in test_filenames]==[item.split('.')[0] for item in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:55.692485Z",
     "iopub.status.busy": "2026-01-25T12:10:55.691650Z",
     "iopub.status.idle": "2026-01-25T12:10:55.698411Z",
     "shell.execute_reply": "2026-01-25T12:10:55.697690Z",
     "shell.execute_reply.started": "2026-01-25T12:10:55.692456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set(), set())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_filenames).intersection(set(valid_filenames)),\\\n",
    "set(valid_filenames).intersection(set(test_filenames)),\\\n",
    "set(test_filenames).intersection(set(train_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:56.106864Z",
     "iopub.status.busy": "2026-01-25T12:10:56.106287Z",
     "iopub.status.idle": "2026-01-25T12:10:56.126572Z",
     "shell.execute_reply": "2026-01-25T12:10:56.126033Z",
     "shell.execute_reply.started": "2026-01-25T12:10:56.106841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['filenames'] = train_filenames + valid_filenames + test_filenames\n",
    "df['labelnames'] = train_labels + valid_labels + test_labels\n",
    "df['train_id'] = [0]*len(train_filenames) + [1]*len(valid_filenames) + [2]*len(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:57.653708Z",
     "iopub.status.busy": "2026-01-25T12:10:57.653413Z",
     "iopub.status.idle": "2026-01-25T12:10:57.673376Z",
     "shell.execute_reply": "2026-01-25T12:10:57.672690Z",
     "shell.execute_reply.started": "2026-01-25T12:10:57.653683Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>labelnames</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1670-_png_jpg.rf.0463edb430019e01ec79eed27a63...</td>\n",
       "      <td>-1670-_png_jpg.rf.0463edb430019e01ec79eed27a63...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1670-_png_jpg.rf.3cb172ea2c4165c19ae2dd498b38...</td>\n",
       "      <td>-1670-_png_jpg.rf.3cb172ea2c4165c19ae2dd498b38...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1670-_png_jpg.rf.7da967f9aeaa62defc36543b9e60...</td>\n",
       "      <td>-1670-_png_jpg.rf.7da967f9aeaa62defc36543b9e60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1670-_png_jpg.rf.b42b26d784545ce1a033679674a4...</td>\n",
       "      <td>-1670-_png_jpg.rf.b42b26d784545ce1a033679674a4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1670-_png_jpg.rf.dd5cb0a4d6da02d34f1dc003fb4e...</td>\n",
       "      <td>-1670-_png_jpg.rf.dd5cb0a4d6da02d34f1dc003fb4e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames  \\\n",
       "0  -1670-_png_jpg.rf.0463edb430019e01ec79eed27a63...   \n",
       "1  -1670-_png_jpg.rf.3cb172ea2c4165c19ae2dd498b38...   \n",
       "2  -1670-_png_jpg.rf.7da967f9aeaa62defc36543b9e60...   \n",
       "3  -1670-_png_jpg.rf.b42b26d784545ce1a033679674a4...   \n",
       "4  -1670-_png_jpg.rf.dd5cb0a4d6da02d34f1dc003fb4e...   \n",
       "\n",
       "                                          labelnames  train_id  \n",
       "0  -1670-_png_jpg.rf.0463edb430019e01ec79eed27a63...         0  \n",
       "1  -1670-_png_jpg.rf.3cb172ea2c4165c19ae2dd498b38...         0  \n",
       "2  -1670-_png_jpg.rf.7da967f9aeaa62defc36543b9e60...         0  \n",
       "3  -1670-_png_jpg.rf.b42b26d784545ce1a033679674a4...         0  \n",
       "4  -1670-_png_jpg.rf.dd5cb0a4d6da02d34f1dc003fb4e...         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:57.946288Z",
     "iopub.status.busy": "2026-01-25T12:10:57.945765Z",
     "iopub.status.idle": "2026-01-25T12:10:57.966866Z",
     "shell.execute_reply": "2026-01-25T12:10:57.966305Z",
     "shell.execute_reply.started": "2026-01-25T12:10:57.946261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id\n",
       "0    2605\n",
       "1     114\n",
       "2      82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of train valid and test sets\n",
    "df.train_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:58.379174Z",
     "iopub.status.busy": "2026-01-25T12:10:58.378860Z",
     "iopub.status.idle": "2026-01-25T12:10:58.605437Z",
     "shell.execute_reply": "2026-01-25T12:10:58.604796Z",
     "shell.execute_reply.started": "2026-01-25T12:10:58.379140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Train-Val-Test Split'}, xlabel='train_id'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.train_id.value_counts().plot(kind = 'bar', title = 'Train-Val-Test Split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:10:59.014351Z",
     "iopub.status.busy": "2026-01-25T12:10:59.013626Z",
     "iopub.status.idle": "2026-01-25T12:10:59.035294Z",
     "shell.execute_reply": "2026-01-25T12:10:59.034586Z",
     "shell.execute_reply.started": "2026-01-25T12:10:59.014324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "ppe_data = dict(train = train_path,\n",
    "                    val = valid_path,\n",
    "                    test = test_path,\n",
    "                   nc = len(class_names),\n",
    "                   names = class_names)\n",
    "with open('ppe_data.yaml', 'w') as output:\n",
    "    yaml.dump(ppe_data, output, default_flow_style = True)\n",
    "\n",
    "yaml_path=\"/kaggle/working/ppe_data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T11:51:00.930956Z",
     "iopub.status.busy": "2026-01-22T11:51:00.930641Z",
     "iopub.status.idle": "2026-01-22T11:51:01.063394Z",
     "shell.execute_reply": "2026-01-22T11:51:01.062585Z",
     "shell.execute_reply.started": "2026-01-22T11:51:00.930927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{names: [Hardhat, Mask, NO-Hardhat, NO-Mask, NO-Safety Vest, Person, Safety Cone,\n",
      "    Safety Vest, machinery, vehicle], nc: 10, test: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/test,\n",
      "  train: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train,\n",
      "  val: /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid}\n"
     ]
    }
   ],
   "source": [
    "%cat /kaggle/working/ppe_data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:11:09.228308Z",
     "iopub.status.busy": "2026-01-25T12:11:09.227768Z",
     "iopub.status.idle": "2026-01-25T12:11:27.466463Z",
     "shell.execute_reply": "2026-01-25T12:11:27.465632Z",
     "shell.execute_reply.started": "2026-01-25T12:11:09.228280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.3/261.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.3/788.3 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "ydata-profiling 4.18.1 requires dacite<2,>=1.9, but you have dacite 1.6.0 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.47.0 which is incompatible.\n",
      "google-colab 1.0.0 requires jupyter-server==2.14.0, but you have jupyter-server 2.12.5 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "fastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics\n",
    "!pip install -q mlflow dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:11:27.468668Z",
     "iopub.status.busy": "2026-01-25T12:11:27.468053Z",
     "iopub.status.idle": "2026-01-25T12:11:37.731762Z",
     "shell.execute_reply": "2026-01-25T12:11:37.731184Z",
     "shell.execute_reply.started": "2026-01-25T12:11:27.468640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import mlflow \n",
    "import dagshub\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagshub.init(repo_owner='YassineBen-Yahia',\n",
    "            repo_name='construction-site-safety',\n",
    "            mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:11:54.067325Z",
     "iopub.status.busy": "2026-01-25T12:11:54.066572Z",
     "iopub.status.idle": "2026-01-25T12:11:59.740579Z",
     "shell.execute_reply": "2026-01-25T12:11:59.739972Z",
     "shell.execute_reply.started": "2026-01-25T12:11:54.067295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def train_yolo_model(\n",
    "    model_name='yolov8n.pt',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    optimizer='auto',\n",
    "    lr0=0.01,\n",
    "    experiment_name='construction-safety',\n",
    "    run_name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a YOLO model with MLflow tracking\n",
    "    \"\"\"\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "    # Set MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=run_name or f\"{model_name.replace('.pt', '')}_{epochs}ep\"):\n",
    "        \n",
    "        # Log parameters\n",
    "        params = {\n",
    "            'model_name': model_name,\n",
    "            'epochs': epochs,\n",
    "            'imgsz': imgsz,\n",
    "            'batch': batch,\n",
    "            'optimizer': optimizer,\n",
    "            'lr0': lr0,\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Add tags for better organization\n",
    "        mlflow.set_tag(\"model_variant\", model_name.replace('.pt', ''))\n",
    "        mlflow.set_tag(\"framework\", \"YOLOv8\")\n",
    "        \n",
    "        # Initialize YOLO model\n",
    "        model = YOLO(model_name)\n",
    "        \n",
    "        # Custom callback for epoch-level tracking\n",
    "        def on_train_epoch_end(trainer):\n",
    "            \"\"\"Callback to log metrics after each epoch\"\"\"\n",
    "            epoch = trainer.epoch\n",
    "            metrics = trainer.metrics\n",
    "            \n",
    "            # Log training metrics per epoch\n",
    "            epoch_metrics = {\n",
    "                'train/box_loss': trainer.loss_items[0] if hasattr(trainer, 'loss_items') else 0,\n",
    "                'train/cls_loss': trainer.loss_items[1] if hasattr(trainer, 'loss_items') and len(trainer.loss_items) > 1 else 0,\n",
    "                'train/dfl_loss': trainer.loss_items[2] if hasattr(trainer, 'loss_items') and len(trainer.loss_items) > 2 else 0,\n",
    "            }\n",
    "            \n",
    "            # Log validation metrics if available\n",
    "            if hasattr(metrics, 'results_dict'):\n",
    "                results = metrics.results_dict\n",
    "                epoch_metrics.update({\n",
    "                    'val/mAP50': results.get('metrics/mAP50(B)', 0),\n",
    "                    'val/mAP50-95': results.get('metrics/mAP50-95(B)', 0),\n",
    "                    'val/precision': results.get('metrics/precision(B)', 0),\n",
    "                    'val/recall': results.get('metrics/recall(B)', 0),\n",
    "                })\n",
    "            \n",
    "            # Log learning rate\n",
    "            if hasattr(trainer.optimizer, 'param_groups'):\n",
    "                epoch_metrics['learning_rate'] = trainer.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Log all metrics with step (epoch number)\n",
    "            mlflow.log_metrics(epoch_metrics, step=epoch)\n",
    "            \n",
    "            print(f\"Epoch {epoch}: Logged metrics to MLflow/DagShub\")\n",
    "        \n",
    "        # Add callback to model\n",
    "        model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
    "        \n",
    "        # Train the model\n",
    "        results = model.train(\n",
    "            data=yaml_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch,\n",
    "            optimizer=optimizer,\n",
    "            lr0=lr0,\n",
    "            project='runs/train',\n",
    "            name=run_name or model_name.replace('.pt', ''),\n",
    "            save=True,\n",
    "            save_period=10,\n",
    "            plots=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Get best model path\n",
    "        best_model_path = Path(model.trainer.save_dir) / 'weights' / 'best.pt'\n",
    "        last_model_path = Path(model.trainer.save_dir) / 'weights' / 'last.pt'\n",
    "        \n",
    "        # Log final summary metrics\n",
    "        metrics_file = Path(model.trainer.save_dir) / 'results.csv'\n",
    "        if metrics_file.exists():\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(metrics_file)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            # Log best metrics (not just final)\n",
    "            if 'metrics/mAP50-95(B)' in df.columns:\n",
    "                best_epoch = df['metrics/mAP50-95(B)'].idxmax()\n",
    "                best_metrics = {\n",
    "                    'best/mAP50': df['metrics/mAP50(B)'].iloc[best_epoch],\n",
    "                    'best/mAP50-95': df['metrics/mAP50-95(B)'].iloc[best_epoch],\n",
    "                    'best/precision': df['metrics/precision(B)'].iloc[best_epoch],\n",
    "                    'best/recall': df['metrics/recall(B)'].iloc[best_epoch],\n",
    "                    'best/epoch': best_epoch,\n",
    "                }\n",
    "                mlflow.log_metrics(best_metrics)\n",
    "            \n",
    "            # Also log final metrics\n",
    "            final_metrics = {\n",
    "                'final/mAP50': df['metrics/mAP50(B)'].iloc[-1] if 'metrics/mAP50(B)' in df.columns else 0,\n",
    "                'final/mAP50-95': df['metrics/mAP50-95(B)'].iloc[-1] if 'metrics/mAP50-95(B)' in df.columns else 0,\n",
    "                'final/precision': df['metrics/precision(B)'].iloc[-1] if 'metrics/precision(B)' in df.columns else 0,\n",
    "                'final/recall': df['metrics/recall(B)'].iloc[-1] if 'metrics/recall(B)' in df.columns else 0,\n",
    "            }\n",
    "            mlflow.log_metrics(final_metrics)\n",
    "        \n",
    "        # Log model artifacts\n",
    "        if best_model_path.exists():\n",
    "            mlflow.log_artifact(str(best_model_path), 'models')\n",
    "        if last_model_path.exists():\n",
    "            mlflow.log_artifact(str(last_model_path), 'models')\n",
    "        \n",
    "        # Log ALL training plots\n",
    "        plots_dir = Path(model.trainer.save_dir)\n",
    "        plot_patterns = ['*.png', '*.jpg', '*.jpeg']\n",
    "        for pattern in plot_patterns:\n",
    "            for plot_file in plots_dir.glob(pattern):\n",
    "                mlflow.log_artifact(str(plot_file), 'plots')\n",
    "        \n",
    "        # Log results CSV for reference\n",
    "        if metrics_file.exists():\n",
    "            mlflow.log_artifact(str(metrics_file), 'metrics')\n",
    "        \n",
    "        # Log model to MLflow Model Registry\n",
    "        try:\n",
    "            mlflow.pytorch.log_model(\n",
    "                pytorch_model=best_model,\n",
    "                artifact_path='best_model',\n",
    "                registered_model_name=f\"yolo-construction-safety-{model_name.replace('.pt', '')}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not register model: {e}\")\n",
    "        \n",
    " \n",
    "        print(f\" MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "        print(f\" Experiment: {experiment_name}\")\n",
    "        print(f\" Run ID: {mlflow.active_run().info.run_id}\")\n",
    "        \n",
    "        return results, best_model_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T12:11:59.742314Z",
     "iopub.status.busy": "2026-01-25T12:11:59.741755Z",
     "iopub.status.idle": "2026-01-25T12:11:59.750146Z",
     "shell.execute_reply": "2026-01-25T12:11:59.749500Z",
     "shell.execute_reply.started": "2026-01-25T12:11:59.742285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_experiments():\n",
    "    \"\"\"Run experiments with different YOLO models\"\"\"\n",
    "    \n",
    "    models_to_test = [\n",
    "        {'model_name': 'yolov8n.pt', 'batch': 16, 'epochs': 60},  # Nano \n",
    "        {'model_name': 'yolov8s.pt', 'batch': 16, 'epochs': 70},  # Small\n",
    "        {'model_name': 'yolov8m.pt', 'batch': 8, 'epochs': 70},   # Medium\n",
    "        # {'model_name': 'yolov8l.pt', 'batch': 4, 'epochs': 100},  # Large\n",
    "        # {'model_name': 'yolov8x.pt', 'batch': 2, 'epochs': 100},  \n",
    "    ]\n",
    "    \n",
    "    for model_config in models_to_test:\n",
    "        print(\"\\n\")\n",
    "        print(f\"Training {model_config['model_name']}\")\n",
    "       \n",
    "        \n",
    "        train_yolo_model(\n",
    "            model_name=model_config['model_name'],\n",
    "            epochs=model_config['epochs'],\n",
    "            batch=model_config['batch'],\n",
    "            imgsz=640,\n",
    "            optimizer='auto',\n",
    "            lr0=0.01,\n",
    "            experiment_name='construction-safety',\n",
    "            run_name=f\"{model_config['model_name'].replace('.pt', '')}_e{model_config['epochs']}_b{model_config['batch']}\" \n",
    "        )\n",
    "\n",
    "\n",
    "def compare_models():\n",
    "    \"\"\"Compare all models from MLflow\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Get all runs from the experiment\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment = client.get_experiment_by_name('construction-safety')\n",
    "    \n",
    "    if experiment:\n",
    "        runs = client.search_runs(\n",
    "            experiment_ids=[experiment.experiment_id],\n",
    "            order_by=[\"metrics.final_mAP50-95 DESC\"]\n",
    "        )\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = []\n",
    "        for run in runs:\n",
    "            comparison_data.append({\n",
    "                'run_id': run.info.run_id,\n",
    "                'model': run.data.params.get('model_name', 'N/A'),\n",
    "                'mAP50': run.data.metrics.get('final_mAP50', 0),\n",
    "                'mAP50-95': run.data.metrics.get('final_mAP50-95', 0),\n",
    "                'precision': run.data.metrics.get('final_precision', 0),\n",
    "                'recall': run.data.metrics.get('final_recall', 0),\n",
    "                'epochs': run.data.params.get('epochs', 0),\n",
    "                'batch': run.data.params.get('batch', 0),\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(comparison_data)\n",
    "        print(\"\\n Model Comparison:\")\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Save comparison\n",
    "        df.to_csv('model_comparison.csv', index=False)\n",
    "        print(\"\\n Comparison saved to model_comparison.csv\")\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"No experiment found!\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2026-01-25T13:35:50.875Z",
     "iopub.execute_input": "2026-01-25T12:12:04.835711Z",
     "iopub.status.busy": "2026-01-25T12:12:04.835424Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training yolov8m.pt\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8m.pt to 'yolov8m.pt': 100% ━━━━━━━━━━━━ 49.7MB 286.5MB/s 0.2s0.1s<0.1s\n",
      "Ultralytics 8.4.7 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/ppe_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=70, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolov8m_e70_b8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/runs/train/yolov8m_e70_b8, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 29.6MB/s 0.0s\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3781486  ultralytics.nn.modules.head.Detect           [10, 16, None, [192, 384, 576]]\n",
      "Model summary: 170 layers, 25,862,110 parameters, 25,862,094 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ━━━━━━━━━━━━ 5.3MB 93.9MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 16.9±3.0 MB/s, size: 52.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/labels... 2605 images, 6 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2605/2605 402.1it/s 6.5s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train/images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 1 duplicate labels removed\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/train is not writable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.9±2.3 ms, read: 14.6±7.3 MB/s, size: 51.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid/labels... 114 images, 10 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 114/114 300.6it/s 0.4ss\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/construction-site-safety-image-dataset-roboflow/css-data/valid is not writable, cache not saved.\n",
      "Plotting labels to /kaggle/working/runs/detect/runs/train/yolov8m_e70_b8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.000714, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/25 12:12:28 INFO mlflow.bedrock: Enabled auto-tracing for Bedrock. Note that MLflow can only trace boto3 service clients that are created after this call. If you have already created one, please recreate the client by calling `boto3.client`.\n",
      "2026/01/25 12:12:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for boto3.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769343150.276944      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769343150.323647      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769343150.710158      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769343150.710187      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769343150.710190      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769343150.710193      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026/01/25 12:12:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2026/01/25 12:12:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for pytorch_lightning.\n",
      "2026/01/25 12:12:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2026/01/25 12:12:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2026/01/25 12:12:45 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n",
      "2026/01/25 12:12:45 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2026/01/25 12:12:45 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(3dbc9b2805fa49c88008f3c672a79612) to https://dagshub.com/YassineBen-Yahia/construction-site-safety.mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/runs/detect/runs/train/yolov8m_e70_b8\u001b[0m\n",
      "Starting training for 70 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/70      3.92G      1.561       3.26      1.633        126        640: 100% ━━━━━━━━━━━━ 326/326 2.3it/s 2:24<0.5s\n",
      "Epoch 0: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 3.2it/s 2.5s0.3ss\n",
      "                   all        114        697      0.287      0.206      0.227      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/70      4.66G      1.262      1.879      1.435        133        640: 100% ━━━━━━━━━━━━ 326/326 2.6it/s 2:06<0.4s\n",
      "Epoch 1: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.7it/s 1.7s0.3s\n",
      "                   all        114        697      0.611      0.471      0.507      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/70      4.73G      1.124      1.426      1.334         99        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 2:01<0.4ss\n",
      "Epoch 2: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.8it/s 1.7s0.2s\n",
      "                   all        114        697       0.73      0.597      0.662      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/70       4.8G       1.08       1.22       1.28         55        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 1:60<0.3ss\n",
      "Epoch 3: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s0.2s\n",
      "                   all        114        697      0.777      0.681      0.721      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/70      4.86G      1.036      1.102       1.25        151        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 2:00<0.3ss\n",
      "Epoch 4: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s0.2s\n",
      "                   all        114        697      0.864      0.667      0.753       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/70      4.93G      1.014      1.011      1.233        110        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 1:60<0.3ss\n",
      "Epoch 5: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s0.2s\n",
      "                   all        114        697      0.862      0.693      0.776      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/70         5G      0.979      0.946      1.215         67        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 1:60<0.4ss\n",
      "Epoch 6: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 5.0it/s 1.6s0.2s\n",
      "                   all        114        697       0.87      0.717      0.806       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/70      5.06G     0.9664     0.9005      1.196         89        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 2:00<0.3ss\n",
      "Epoch 7: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s0.2s\n",
      "                   all        114        697      0.884       0.71      0.799      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/70      5.13G     0.9463     0.8535      1.182        127        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 2:00<0.3ss\n",
      "Epoch 8: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 5.0it/s 1.6s0.2s\n",
      "                   all        114        697      0.852      0.741      0.803      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/70       5.2G     0.9288     0.8235      1.173         70        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 2:00<0.3ss\n",
      "Epoch 9: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s0.2s\n",
      "                   all        114        697      0.854      0.747      0.813       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/70      5.94G     0.9099     0.7996      1.163         64        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 1:60<0.4ss\n",
      "Epoch 10: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 4.9it/s 1.6s0.2s\n",
      "                   all        114        697      0.874      0.762      0.831      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/70      6.01G     0.8944     0.7678      1.144         96        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 1:60<0.3ss\n",
      "Epoch 11: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 5.0it/s 1.6s0.2s\n",
      "                   all        114        697      0.881      0.776      0.839      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/70      6.07G     0.8758     0.7417      1.138        123        640: 100% ━━━━━━━━━━━━ 326/326 2.7it/s 2:00<0.3ss\n",
      "Epoch 12: Logged metrics to MLflow/DagShub\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 5.0it/s 1.6s0.2s\n",
      "                   all        114        697      0.897      0.752      0.833      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/70      6.13G     0.8785     0.7254      1.127        217        640: 67% ━━━━━━━╸──── 217/326 2.9it/s 1:20<38.2ss"
     ]
    }
   ],
   "source": [
    "run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-25T12:10:40.788058Z",
     "iopub.status.idle": "2026-01-25T12:10:40.788363Z",
     "shell.execute_reply": "2026-01-25T12:10:40.788220Z",
     "shell.execute_reply.started": "2026-01-25T12:10:40.788207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "compare_models()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2919095,
     "sourceId": 5048288,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
